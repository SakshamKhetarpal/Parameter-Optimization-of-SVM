# -*- coding: utf-8 -*-
"""optimisation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G4YiRvMXqwpWIA0cY3kl45P254uiFc55
"""

import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.svm import SVR
from scipy.stats import uniform
 
# Load the data
df = pd.read_csv("/Shill Bidding Dataset.csv")
df = df.drop(['Record_ID', 'Auction_ID', 'Bidder_ID'], axis=1)
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# Define the hyperparameter search space
param_distributions = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
                       'C': uniform(0.01, 10),
                       'epsilon': uniform(0.01, 1.0)}

# Initialize lists to store the best parameters for each sample
best_params_list = []

# Loop over 10 different random samples
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
    
    # Set up the SVR model with random search for hyperparameter optimization
    svr = SVR()
    random_search = RandomizedSearchCV(svr, param_distributions, n_iter=1000, cv=5, random_state=i)
    
    # Fit the SVR model on the training set with hyperparameter optimization
    random_search.fit(X_train, y_train)
    
    # Store the best parameters and accuracy for this sample
    best_params = random_search.best_params_
    best_params['sample'] = i + 1
    best_params['accuracy'] = random_search.best_score_
    best_params_list.append(best_params)
    
# Create a table with sample number, best kernel, best C, and best epsilon
table = pd.DataFrame(best_params_list)[['sample', 'accuracy', 'kernel', 'C', 'epsilon']]
table['sample'] = 'Sample ' + table['sample'].astype(str)

print(table)